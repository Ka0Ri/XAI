{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models for RMS Titanic, snippets for Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dalex as dx\n",
    "titanic = dx.datasets.load_titanic()\n",
    "X = titanic.drop(columns='survived')\n",
    "y = titanic.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      gender   age             class     embarked   fare  sibsp  parch\n",
      "0       male  42.0               3rd  Southampton   7.11      0      0\n",
      "1       male  13.0               3rd  Southampton  20.05      0      2\n",
      "2       male  16.0               3rd  Southampton  20.05      1      1\n",
      "3     female  39.0               3rd  Southampton  20.05      1      1\n",
      "4     female  16.0               3rd  Southampton   7.13      0      0\n",
      "...      ...   ...               ...          ...    ...    ...    ...\n",
      "2202    male  41.0         deck crew      Belfast   0.00      0      0\n",
      "2203    male  40.0  victualling crew  Southampton   0.00      0      0\n",
      "2204    male  32.0  engineering crew  Southampton   0.00      0      0\n",
      "2205    male  20.0  restaurant staff  Southampton   0.00      0      0\n",
      "2206    male  26.0  restaurant staff  Southampton   0.00      0      0\n",
      "\n",
      "[2207 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "preprocess = make_column_transformer(\n",
    "    (StandardScaler(), ['age', 'fare', 'parch', 'sibsp']),\n",
    "    (OneHotEncoder(), ['gender', 'class', 'embarked']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('standardscaler',\n",
       "                                                  StandardScaler(),\n",
       "                                                  ['age', 'fare', 'parch',\n",
       "                                                   'sibsp']),\n",
       "                                                 ('onehotencoder',\n",
       "                                                  OneHotEncoder(),\n",
       "                                                  ['gender', 'class',\n",
       "                                                   'embarked'])])),\n",
       "                ('logisticregression', LogisticRegression())])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "titanic_lr = make_pipeline(\n",
    "    preprocess,\n",
    "    LogisticRegression(penalty = 'l2'))\n",
    "titanic_lr.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('standardscaler',\n",
       "                                                  StandardScaler(),\n",
       "                                                  ['age', 'fare', 'parch',\n",
       "                                                   'sibsp']),\n",
       "                                                 ('onehotencoder',\n",
       "                                                  OneHotEncoder(),\n",
       "                                                  ['gender', 'class',\n",
       "                                                   'embarked'])])),\n",
       "                ('randomforestclassifier',\n",
       "                 RandomForestClassifier(max_depth=3, n_estimators=500))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "titanic_rf = make_pipeline(\n",
    "    preprocess,\n",
    "    RandomForestClassifier(max_depth = 3, n_estimators = 500))\n",
    "titanic_rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient boosting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('standardscaler',\n",
       "                                                  StandardScaler(),\n",
       "                                                  ['age', 'fare', 'parch',\n",
       "                                                   'sibsp']),\n",
       "                                                 ('onehotencoder',\n",
       "                                                  OneHotEncoder(),\n",
       "                                                  ['gender', 'class',\n",
       "                                                   'embarked'])])),\n",
       "                ('gradientboostingclassifier', GradientBoostingClassifier())])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "titanic_gbc = make_pipeline(\n",
    "    preprocess,\n",
    "    GradientBoostingClassifier(n_estimators = 100))\n",
    "titanic_gbc.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support vector machine model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('standardscaler',\n",
       "                                                  StandardScaler(),\n",
       "                                                  ['age', 'fare', 'parch',\n",
       "                                                   'sibsp']),\n",
       "                                                 ('onehotencoder',\n",
       "                                                  OneHotEncoder(),\n",
       "                                                  ['gender', 'class',\n",
       "                                                   'embarked'])])),\n",
       "                ('svc', SVC(probability=True))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "titanic_svm = make_pipeline(\n",
    "    preprocess,\n",
    "    SVC(probability = True))\n",
    "titanic_svm.fit(X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.78328913, 0.21671087]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "johnny_d = pd.DataFrame({'gender': ['male'],\n",
    "                       'age'     : [8],\n",
    "                       'class'   : ['1st'],\n",
    "                       'embarked': ['Southampton'],\n",
    "                       'fare'    : [72],\n",
    "                       'sibsp'   : [0],\n",
    "                       'parch'   : [0]},\n",
    "                      index = ['JohnnyD'])\n",
    "\n",
    "titanic_lr.predict_proba(johnny_d)\n",
    "# array([[0.35884528, 0.64115472]])\n",
    "titanic_rf.predict_proba(johnny_d)\n",
    "# array([[0.63028556, 0.36971444]])\n",
    "titanic_gbc.predict_proba(johnny_d)\n",
    "# array([[0.1567194, 0.8432806]])\n",
    "titanic_svm.predict_proba(johnny_d)\n",
    "# array([[0.78308146, 0.21691854]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.81543577, 0.18456423]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "henry = pd.DataFrame({'gender'   : ['male'],\n",
    "                       'age'     : [47],\n",
    "                       'class'   : ['1st'],\n",
    "                       'embarked': ['Cherbourg'],\n",
    "                       'fare'    : [25],\n",
    "                       'sibsp'   : [0],\n",
    "                       'parch'   : [0]},\n",
    "                      index = ['Henry'])\n",
    "titanic_lr.predict_proba(henry)\n",
    "# array([[0.56798421 0.43201579]])\n",
    "titanic_rf.predict_proba(henry)\n",
    "# array([[0.69917845 0.30082155]])\n",
    "titanic_gbc.predict_proba(henry)\n",
    "# array([[0.78542886 0.21457114]])\n",
    "titanic_svm.predict_proba(henry)\n",
    "# array([[0.81725832 0.18274168]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models' explainers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 2207 rows 7 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.Series. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 2207 values\n",
      "  -> model_class       : sklearn.ensemble._forest.RandomForestClassifier (default)\n",
      "  -> label             : Titanic RF Pipeline\n",
      "  -> predict function  : <function yhat_proba_default at 0x0000025374087040> will be used (default)\n",
      "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
      "  -> predicted values  : min = 0.164, mean = 0.322, max = 0.885\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -0.828, mean = 0.000653, max = 0.832\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n",
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 2207 rows 7 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.Series. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 2207 values\n",
      "  -> model_class       : sklearn.linear_model._logistic.LogisticRegression (default)\n",
      "  -> label             : Titanic LR Pipeline\n",
      "  -> predict function  : <function yhat_proba_default at 0x0000025374087040> will be used (default)\n",
      "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
      "  -> predicted values  : min = 0.009, mean = 0.322, max = 0.97\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -0.96, mean = -5.83e-07, max = 0.964\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n",
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 2207 rows 7 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.Series. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 2207 values\n",
      "  -> model_class       : sklearn.ensemble._gb.GradientBoostingClassifier (default)\n",
      "  -> label             : Titanic GBC Pipeline\n",
      "  -> predict function  : <function yhat_proba_default at 0x0000025374087040> will be used (default)\n",
      "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
      "  -> predicted values  : min = 0.0206, mean = 0.322, max = 0.99\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -0.944, mean = -2.6e-05, max = 0.936\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n",
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 2207 rows 7 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.Series. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 2207 values\n",
      "  -> model_class       : sklearn.svm._classes.SVC (default)\n",
      "  -> label             : Titanic SVM Pipeline\n",
      "  -> predict function  : <function yhat_proba_default at 0x0000025374087040> will be used (default)\n",
      "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
      "  -> predicted values  : min = 0.0619, mean = 0.323, max = 0.933\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -0.885, mean = -0.000443, max = 0.897\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n"
     ]
    }
   ],
   "source": [
    "titanic_rf_exp = dx.Explainer(titanic_rf, \n",
    "                    X, y, label = \"Titanic RF Pipeline\")\n",
    "titanic_lr_exp = dx.Explainer(titanic_lr, \n",
    "                    X, y, label = \"Titanic LR Pipeline\")\n",
    "titanic_gbc_exp = dx.Explainer(titanic_gbc, \n",
    "                    X, y, label = \"Titanic GBC Pipeline\")\n",
    "titanic_svm_exp = dx.Explainer(titanic_svm, \n",
    "                    X, y, label = \"Titanic SVM Pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartment prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dalex as dx\n",
    "apartments = dx.datasets.load_apartments()\n",
    "X = apartments.drop(columns='m2_price')\n",
    "y = apartments['m2_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "preprocess = make_column_transformer(\n",
    "    (StandardScaler(), ['construction_year', 'surface', 'floor', 'no_rooms']),\n",
    "    (OneHotEncoder(), ['district']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('standardscaler',\n",
       "                                                  StandardScaler(),\n",
       "                                                  ['construction_year',\n",
       "                                                   'surface', 'floor',\n",
       "                                                   'no_rooms']),\n",
       "                                                 ('onehotencoder',\n",
       "                                                  OneHotEncoder(),\n",
       "                                                  ['district'])])),\n",
       "                ('linearregression', LinearRegression())])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "apartments_lm = make_pipeline(\n",
    "    preprocess,\n",
    "    LinearRegression())\n",
    "apartments_lm.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('standardscaler',\n",
       "                                                  StandardScaler(),\n",
       "                                                  ['construction_year',\n",
       "                                                   'surface', 'floor',\n",
       "                                                   'no_rooms']),\n",
       "                                                 ('onehotencoder',\n",
       "                                                  OneHotEncoder(),\n",
       "                                                  ['district'])])),\n",
       "                ('randomforestregressor',\n",
       "                 RandomForestRegressor(max_depth=3, n_estimators=500))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "apartments_rf = make_pipeline(\n",
    "    preprocess,\n",
    "    RandomForestRegressor(max_depth = 3, n_estimators = 500))\n",
    "apartments_rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('standardscaler',\n",
       "                                                  StandardScaler(),\n",
       "                                                  ['construction_year',\n",
       "                                                   'surface', 'floor',\n",
       "                                                   'no_rooms']),\n",
       "                                                 ('onehotencoder',\n",
       "                                                  OneHotEncoder(),\n",
       "                                                  ['district'])])),\n",
       "                ('svr', SVR())])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "apartments_svm = make_pipeline(\n",
    "    preprocess,\n",
    "    SVR())\n",
    "apartments_svm.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4820.00943156, 3292.67756996, 2717.90972101, ..., 4836.44370353,\n",
       "       3191.69063189, 5157.93680175])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apartments_test = dx.datasets.load_apartments_test()\n",
    "apartments_test = apartments_test.drop(columns='m2_price')\n",
    "\n",
    "apartments_lm.predict(apartments_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 1000 rows 5 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.Series. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 1000 values\n",
      "  -> model_class       : sklearn.linear_model._base.LinearRegression (default)\n",
      "  -> label             : Apartments LM Pipeline\n",
      "  -> predict function  : <function yhat_default at 0x000002537407CF70> will be used (default)\n",
      "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
      "  -> predicted values  : min = 1.78e+03, mean = 3.49e+03, max = 6.18e+03\n",
      "  -> model type        : regression will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -2.47e+02, mean = 3.67e-13, max = 4.69e+02\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n",
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 1000 rows 5 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.Series. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 1000 values\n",
      "  -> model_class       : sklearn.ensemble._forest.RandomForestRegressor (default)\n",
      "  -> label             : Apartments RF Pipeline\n",
      "  -> predict function  : <function yhat_default at 0x000002537407CF70> will be used (default)\n",
      "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
      "  -> predicted values  : min = 2.73e+03, mean = 3.49e+03, max = 6.05e+03\n",
      "  -> model type        : regression will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -1.12e+03, mean = 1.87, max = 1.45e+03\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n",
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 1000 rows 5 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.Series. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 1000 values\n",
      "  -> model_class       : sklearn.svm._classes.SVR (default)\n",
      "  -> label             : Apartments SVM Pipeline\n",
      "  -> predict function  : <function yhat_default at 0x000002537407CF70> will be used (default)\n",
      "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
      "  -> predicted values  : min = 3.3e+03, mean = 3.38e+03, max = 3.46e+03\n",
      "  -> model type        : regression will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -1.72e+03, mean = 1.08e+02, max = 3.14e+03\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n"
     ]
    }
   ],
   "source": [
    "apartments_lm_exp = dx.Explainer(apartments_lm, X, y, \n",
    "                      label = \"Apartments LM Pipeline\")\n",
    "apartments_rf_exp = dx.Explainer(apartments_rf, X, y, \n",
    "                      label = \"Apartments RF Pipeline\")\n",
    "apartments_svm_exp = dx.Explainer(apartments_svm, X, y, \n",
    "                      label = \"Apartments SVM Pipeline\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2391778b685347cadac7093f2020ff559e06ee771e9dafe75e8ab1e16b0e24d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
